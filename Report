
Report by Pratibha 

Introduction

Twitter is an online micro-blogging and social-networking platform which allows users to write short status updates of maximum length 
140 characters. It is a rapidly expanding service with over 200 million registered users out of which 100 million are active users and 
half of them log on twitter on a daily basis - generating nearly 250 million tweets per day . Due to this huge amount of users we can
achieve a reflection of public sentiment by analysing the sentiments expressed in the form of tweets. Analysing the public sentiment is
important for many applications such as firms trying to find out the feedback of their products in the market, predicting political 
elections and predicting socioeconomic phenomena like stock exchange. The aim of this assignment is to use Apache Spark's MLlib 
classifiers to determine the sentiment of a given tweet.

Problem Statement

The problem statement is , given a message, classify whether the message is of positive (1), negative (0) sentiment by using 
Apache Spark's mllib Naive Bayes classifier, Logistic Regression classifer and Decision tree classifer.

Domain Introduction

Analyzing tweet sentiments comes under the domain of “Pattern Classification” and “Data Mining”. The process of finding "useful" 
patters can be done using Supervised or Unsupervised learning methods. In supervised learning, the output datasets are provided which
are used to train the machine and get the desired outputs whereas in unsupervised learning no datasets are provided, instead the data
is clustered into different classes .Here , we are making use of “Machine Learning” techniques such as Naive Bayes, Logistic Regression,
and Decision Tree for accurately classifying the given test data according to whichever pattern model best describes them.


The Apache Spark Setup
• Install Apache Spark 1.6.1 
• Install nltk for the purpose of Porterstemmer 
• Install jupyter notebook
• Connect your VM to jupyter notebook using secure shell
• Resolve dependencies as and when errors are thrown, like numpy 
• Install matplotlib libraries for the graphs to be plotted


1. Tweet processing steps

Tweet text formatting techniques are :

2)Import the necessary libraries which are required for reading the tweets,cleaning the tweets like nltk, regular expressions and the
spark’s mllib which are required for tweet classification.

3)Load the training and testing dataset as an RDD using SparkContext object sc.

4)Parse each tweet by converting to lowercase and do the following processing steps which are defined in cleantweets() function.
• Replace a word containing ‘http’/’https’ with URL using regular expressions as we are interested in analyzing the tweet text only.
• Replace a word containing ‘www.’ with URL using regular expressions as we are interested in analyzing the tweet text only.
• Replace a word containing ‘@’ with AT_USER as we are interested in analyzing the tweet text only.
• Tokenization/Lexical analysis is the process of breaking a stream of text into words, symbols and other meaningful elements called “tokens”. Tokens can be separated by whitespace characters and/or punctuation characters. The list of tokens becomes input for further processing such as parsing or text mining.
• For each token in a tweet do the below processing steps:
a. Stemming - It is the process of normalizing a text by reducing a derived word to its root or stem. For example a stemmer would reduce the phrases “feeling”, “feels” to the root word “feel”.This process makes the comparison between words simpler, as we do not need to deal with complex grammatical transformations of the word. Here, we are using nltk’s Porterstemmer to perform stemming.
b. Further Formatting 
• Replace #token with token .
• Ignore words which does not start with alphabets using isalpha() function.
•Check for any stopwords like ‘a’,’an’,’me’,’the’ in the stopwords list and remove them as they do not provide any valuable information.
• Remove all the punctuations from the tokens as they do not provide any valuable information.
• Replace all multiple occurrences(more than 2) of characters to just 2.

Finally, the output of the function is the clean tweet which can be further considered for analysis.


2. Feature space

HashingTF is a Transformer which takes sets of terms and converts those sets into fixed-length feature vectors. It transforms a
bag of words into a vector of term frequencies by applying a hash function to each term.Unigrams are considered here.The size of the
feature space is 50,000 to lessen the chances of collisions, because the vector has a finite number of elements, it's possible that
two terms will map to the same hashed term.


3. Parameter tuning on three classifiers: NB, LOG and DT

For the Decision tree classifier, we have reduced the number of features by trial and error method as a large value would run forever
and the notebook timed out. 


4. Performance Metrics

NB Classifier values 

Naive-Bayes classifier train-train accuracy - 81.3175 

10-fold cross-validation accuracy values are 

Naive-Bayes classifier K-fold accuracy 75.0285207250602 
Naive-Bayes classifier K-fold accuracy 73.97106510351709 
Naive-Bayes classifier K-fold accuracy 75.05233345647088 
Naive-Bayes classifier K-fold accuracy 75.22471198885935 
Naive-Bayes classifier K-fold accuracy 73.80715705765407 
Naive-Bayes classifier K-fold accuracy 74.51632778804684 
Naive-Bayes classifier K-fold accuracy 75.36597677940435 
Naive-Bayes classifier K-fold accuracy 74.80867346938776 
Naive-Bayes classifier K-fold accuracy 74.73111633081963 
Naive-Bayes classifier K-fold accuracy 74.76728310785651 
Naive-Bayes classifier average for K-fold classifier 74.72731658070767 

Naive-Bayes Test accuracy - 79.38718662952647

Performance metrics for Naive-Bayes
•Precision : 0.7934782608695652
•Recall : 0.8021978021978022
•f1-measure: 0.7978142076502732
•Area under ROC: 0.7937542683305395
​ 
LOR Classifier values 

Logistic Regression train-train classifier - 87.36 

10-fold cross-validation accuracy values are 

Logistic Regression classifier K-fold accuracy 71.88322265380278 
Logistic Regression classifier K-fold accuracy 72.70918811388786 
Logistic Regression classifier K-fold accuracy 71.555336455509 
Logistic Regression classifier K-fold accuracy 71.33199799699548 
Logistic Regression classifier K-fold accuracy 71.59815069348994 
Logistic Regression classifier K-fold accuracy 71.11616736190115 
Logistic Regression classifier K-fold accuracy 72.08569628229363 
Logistic Regression classifier K-fold accuracy 71.74314183786443 
Logistic Regression classifier K-fold accuracy 72.44084524863976 
Logistic Regression classifier K-fold accuracy 71.78781433754536 
Logistic Regression classifier average for K-fold classifier 71.82515609819293 

Logistic_Regression Test accuracy - 77.99442896935933

Performance metrics for Logistic Regression
•Precision : 0.7754010695187166
•Recall : 0.7967032967032966
•f1-measure: 0.7859078590785907
•Area under ROC: 0.7797075805550382

DT Classifier values 

Decision tree train-train classifier - 62.21875 

10-fold cross-validation accuracy values are 

Decision tree classifier K-fold accuracy 62.077173640691555 
Decision tree classifier K-fold accuracy 62.432915921288014 
Decision tree classifier K-fold accuracy 61.7165019391968 
Decision tree classifier K-fold accuracy 62.03406566279931 
Decision tree classifier K-fold accuracy 61.32855908136807 
Decision tree classifier K-fold accuracy 61.8779694923731 
Decision tree classifier K-fold accuracy 62.189980158730165 
Decision tree classifier K-fold accuracy 62.116545521744484 
Decision tree classifier K-fold accuracy 63.00227445034117 
Decision tree classifier K-fold accuracy 62.51739405439595 
Decision tree Regression classifier average for K-fold classifier 62.129337992292854 

Decision tree Test accuracy - 60.16713091922006

Performance metrics for Logistic Regression
•Precision : 0.510989010989011
•Recall : 0.6326530612244898
•f1-measure: 0.5653495440729484
•Area under ROC: 0.6064208702348864

•Findings


Classifier                        Naive-Bayes         Logistic_Regression              Decision-tree 
Training Accuracy                   81.3175                  87.36                         62.21875 
10-fold validation Accuracy     74.72731658070767       71.82515609819293             62.129337992292854 
Test Accuracy                   79.38718662952647       77.99442896935933             60.16713091922006 
Precision                       0.7934782608695652      0.7754010695187166            0.510989010989011 
Recall                          0.8021978021978022      0.7967032967032966            0.6326530612244898 
F1 measure                      0.7978142076502732      0.7859078590785907            0.5653495440729484 


From the above comparison table, we can say that when the test is done on the data on which it is trained, logistic-regression
performs really well with accuracy about 87% , but when it is tested using test data which is different from train data, which can 
be seen from Test Accuracy and 10-fold cross-validation Accuracy, Naive-Bayes classifer performs well when compared to
Logistic-Regression and Decision-tree. 

General Confusion Matrix                 Prediction says Yes                Prediction says No 
Observation says Yes                       True positive                     False negative 
Observation says No                        False positive                    True negative 


Confusion Matrix for Naive_Bayes_classifier       Prediction says Positive        Prediction says Negative 
Observation says Positive                                   146                          36 
Observation says Negative                                   38                           139 


Confusion Matrix for logistic-regression classifer       Prediction says Positive       Prediction says Negative 
Observation says Positive                                          145                            37 
Observation says Negative                                           42                            135 


Confusion Matrix for decision-tree classifer              Prediction says Positive       Prediction says Negative 
Observation says Positive                                           93                              54 
Observation says Negative                                           89                              123 

• We can say that Naive-Bayes classifer performs well when compared to logistic-regression classifer and decision-tree beacuse of the 
following observations
• The number of False positives for logistic-regression(42) and decision-tree(89) is more when compared to naive-bayes (38) which
means to say that the Prediction is a "Positive" whereas according to the Observed data it is a "Negative" which is an error 
• The number of False negative for logistic-regression(37) and decision-tree(54) is more when compared to naive-bayes (36) which means
to say that the Prediction is a "Negative" whereas according to the Observed data it is a "Positive" which is an error 


5. Plot training accuracy, 10-fold cross-validation accuracy and test accuracy together using matplotlib 

See Plot attached

By observing the above plot, we can say that logistic-regression classifer overfits the most because it gives a high accuracy on the 
training data but the accuracy decreases when tested using a data different from train data,on the other hand Naive-Bayes classifier 
performs well as it maintains consistency with all the data.


6. Precision, recall, f1-score, confusion matrix (true positive, true negative, false positive, false negative)

Confusion matrix

Confusion Matrix                     Prediction says Positive               Prediction says Negative 
Observation says Positive                True positive                          False negative 
Observation says Negative                False positive                         True negative 

* Precision

Precision (also called positive predictive value) is the fraction of retrieved instances that are relevant.

Here, prediction is given by, true positives/(true positives + false positives)

* Recall

Recall (also known as sensitivity) is the fraction of relevant instances that are retrieved

Here, Recall is given by, true positives/(true positives + false negatives)

* F1 score

F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p and the recall r of the 
test to compute the score: p is the number of correct positive results divided by the number of all positive results, and r is the
number of correct positive results divided by the number of positive results that should have been returned. The F1 score can be
interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst at 0.

Here, F1 score is given by 2*Precision*Recall/(Precision+Recall)


7. ROC curve and report the area under the curve

See ROC curve attached

Receiver Operating Characteristic curve (or ROC curve) is a plot of the true positive rate against the false positive rate for the 
different possible threshold of a diagnostic test.
•A ROC curve demonstrates several things:
1)It shows the tradeoff between sensitivity(Recall) and specificity (any increase in sensitivity will be accompanied by a decrease
in specificity) where Sensitivity= true positives/(true positive + false negative) and
Specificity=true negatives/(true negative + false positives)
2)The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.
3)The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.
4)The slope of the tangent line at a cutpoint gives the likelihood ratio (LR) for that value of the test.
5)The area under the curve is a measure of text accuracy

Naive-Bayes Area under ROC: 0.7937542683305395

Logistic-Regression Area under ROC: 0.7797075805550382

Decision-tree Area under ROC: 0.6064208702348864

By observing the Area under ROC for all the three classifiers, we can determine that Naive_Bayes_classifier is more accurate

By the above graph, we can determine that the test is more accurate as the curve follows the left-hand border and then the top border
of the ROC space


8. Best classifier

Naive-Bayes classifier is the best classifier.The Naive Bayes model assumes each feature to be independent of all other features.Thus,
for example, if you had a feature "best" and another "world's best", then their probabilities would be multiplied as though independent, even though the two are overlapping.By observing the graph(section 5) above we see that logistic-regression overfits the most.An overfit model is one that is too complicated for your data set. When this happens, the regression model becomes tailored to fit the quirks and random noise in the training data rather than reflecting the test data. If we test using a data different from training data, it would have its own quirks, and the original overfit model would not likely fit the new data. The sample size limits the number of terms that you can safely include before you begin to overfit the model.Larger sample sizes allow you to specify more complex models. For trustworthy results,the sample size must be large enough to support the level of complexity that is required by the question. If the sample size isn’t large enough, we won’t be able to fit a model that adequately approximates the true model for your response variable.

Cross-validation is a method by which we can detect if model overfits by determining how well the model performs to a different data
set which was not there in the training data by partitioning the data observations.By observing the plot for 10-fold-cross-validation 
and test accuracy, it is evident that Naive-Bayes classifier performs better than Logistic-Regression and decision-tree.Hence,F1 score
which can be interpreted as a weighted average of the precision and recall is the highest for naive-bayes classifer.




9. Sample tweets and their prediction probabilities

Some 20 correctly classified tweets
•1.4713582481465765e-05 "F*ck Time Warner Cable!!! You f*cking suck balls!!! I have a $700 HD tv & my damn HD channels hardly ever 
come in. Bullshit!!"
•0.00011270974515146502 "I hate Time Warner! Soooo wish I had Vios. Cant watch the fricken Mets game w/o buffering. I feel like im
watching free internet porn."
•0.00016248813230073473 "is being fucked by time warner cable. didnt know modems could explode. and Susan Boyle sucks too!"
•0.00020327942685522717 "i srsly hate the stupid twitter API timeout thing, soooo annoying!!!!! :("
•0.00021157264747809868 "@springsingfiend @dvyers @sethdaggett @jlshack AT&T dropped the ball and isn't supporting crap with the new 
iPhone 3.0... FAIL #att SUCKS!!!"
•0.00029058007594554307 "You guys see this? Why does Time Warner have to suck so much ass? Really wish I could get U-Verse at my 
apartment. http://bit.ly/s594j"
•0.00030099904265909976 "RT @sportsguy33 The upside to Time Warner: unhelpful phone operators superslow on-site service. Crap, that's
not an upside."
•0.00034777656547196716 "OMG - time warner f'ed up my internet install - instead of today its now NEXT saturday - another week w/o
internet! &$*ehfa^V9fhg[*# fml."
•0.0003709619961368655 "NOOOOOOO my DVR just died and I was only half way through the EA presser. Hate you Time Warner"
•0.0003733819080695576 "i hate comcast right now. everything is down cable internet & phone....ughh what am i to do"
•0.00039571885606151083 "THE DENTIST LIED! "" U WON'T FEEL ANY DISCOMORT! PROB WON'T EVEN NEED PAIN PILLS"" MAN U TWIPPIN THIS 
SHIT HURT!! HOW MANY PILLS CAN I TAKE!!"
•0.0006035941086036316 "@Mbjthegreat i really dont want AT&T phone service..they suck when it comes to having a signal"
•0.0006773395978129893 "argghhhh why won't my jquery appear in safari bad safari !!!"
•0.0010068600096215861 "Time Warner cable phone reps r dumber than nails!!!!! UGH! Cable was working 10 mins ago now its not WTF!"
•0.0010254026526196232 "Safari 4 is fast :) Even on my shitty AT&T tethering."
•0.0010307444962566862 "@ Safeway. Place is a nightmare right now. Bumming."
•0.0012333878078318406 "time warner really picks the worst time to not work. all i want to do is get to mtv.com so i can watch the
hills. wtfffff."
•0.00181996172248295 "Trouble in Iran, I see. Hmm. Iran. Iran so far away. #flockofseagullsweregeopoliticallycorrect"
•0.0018791267462519514 "Took the Graduate Field Exam for Computer Science today. Nothing makes you feel like more of an idiot than
lambda calculus."
•0.0019966424715237977 "#wolfram Alpha SUCKS! Even for researchers the information provided is less than you can get from #google or
#wikipedia, totally useless!"

Top 5 correctly classified tweets
•0.9999067671530703 "getting ready to test out some burger receipes this weekend. Bobby Flay has some great receipes to try. Thanks 
Bobby."
•0.9998474558953657 "@cwong08 I have a Kindle2 (& Sony PRS-500). Like it! Physical device feels good. Font is nice. Pg turns are 
snappy enuf. UI a little klunky."
•0.9998150229368572 "Obama is quite a good comedian! check out his dinner speech on CNN :) very funny jokes."
•0.9995385833125675 "@sklososky Thanks so much!!! ...from one of your *very* happy Kindle2 winners ; ) I was so surprised, fabulous. 
Thank you! Best, Kathleen"
•0.9995194175671434 "@SoChi2 I current use the Nikon D90 and love it, but not as much as the Canon 40D/50D. I chose the D90 for the 
video feature. My mistake."

Some 20 incorrectly classified tweets
•0.014057071283084931 "My dad was in NY for a day, we ate at MESA grill last night and met Bobby Flay. So much fun, except I
completely lost my voice today."
•0.021490333357937937 "We went to Stanford University today. Got a tour. Made me want to go back to college. It's also decided all
of our kids will go there."
•0.034591424863606786 "SOOO DISSAPOiNTED THEY SENT DANNY GOKEY HOME... YOU STiLL ROCK ...DANNY ... MY HOMETOWN HERO !! YEAH MiLROCKEE!!"
•0.0387172835343328 "@ atebits I just finished watching your Stanford iPhone Class session. I really appreciate it. You Rock!"
•0.03885040572376286 "The great Indian tamasha truly will unfold from May 16, the result day for Indian General Election."
•0.06438926834013219 "Malcolm Gladwell might be my new man crush"
•0.07942954006769984 "Learning about lambda calculus :)"
•0.08164125974253493 "is studing math ;) tomorrow exam and dentist :)"
•0.09511942196152474 "Safeway is very rock n roll tonight"
•0.10661809060889499 "Prettiest insects EVER - Pink Katydids: http://bit.ly/2Upw2p"
•0.1520327085925114 "RT @shrop: Awesome JQuery reference book for Coda! http://www.macpeeps.com/coda/ #webdesign"
•0.16286273594175527 "@dannygokey I love you DANNY GOKEY!! :)"
•0.17358409639085454 "My wrist still hurts. I have to get it looked at. I HATE the dr/dentist/scary places. :( Time
to watch Eagle eye. If you want to join, txt!"
•0.17763906284669526 "omgg i ohhdee want mcdonalds damn i wonder if its open lol =]"
•0.20217137971581703 "Class... The 50d is supposed to come today :)"
•0.22977129066954602 "yankees won mets lost. its a good day."
•0.23568256726433875 "zomg!!! I have a G2!!!!!!!"
•0.25614066981033995 "#GoogleIO | O3D - Bringing 3d graphics to the browser. Very nice tbh. Funfun."
•0.26092515992841103 "I seriously underestimated Malcolm Gladwell. I want to meet this dude."
•0.29473990505147707 "@matthewcyan I finally got around to using jquery to make my bio collapse. Yay for slide animations."

Top 5 incorrectly classified tweets
•0.9991633208906028 "Cox or Time Warner? Cox is cheaper and gets a B on dslreports. TW is more expensive and gets a C."
•0.9979965271278043 "I still love my Kindle2 but reading The New York Times on it does not feel natural. I miss the Bloomingdale ads."
•0.9932202600197496 "Back from seeing 'Star Trek' and 'Night at the Museum.' 'Star Trek' was amazing, but 'Night at the Museum' was;
eh."
•0.9899347007270659 "I just created my first LaTeX file from scratch. That didn't work out very well. (See @amandabittner , it's a 
great time waster)"
•0.9887543535683618 "looks like summize has gone down. too many tweets from WWDC perhaps?"
